# export HF_HOME="/mnt/data/shuoxing/vllm_frame_select"
# export HF_DATASETS_CACHE="/mnt/data/shuoxing/vllm_frame_select/datasets"
# export HF_TOKEN="your_huggingface_token_here"

# pip install git+https://github.com/LLaVA-VL/LLaVA-NeXT.git
# pip install git+https://github.com/EvolvingLMMs-Lab/lmms-eval.git

nohup env CUDA_VISIBLE_DEVICES=2,3,6,7 uv run accelerate launch --num_processes=4 --main_process_port 12399 -m lmms_eval \
    --model=llava_onevision \
    --model_args=pretrained=lmms-lab/llava-onevision-qwen2-7b-ov,conv_template=qwen_1_5,device_map=auto,model_name=llava_qwen \
    --tasks=longvideobench_val_i \
    --batch_size=1 \
    --output_path=./outputs/llava_onevision_longvideobench

echo ""
echo "=== Recently accessed YAML files (last 10 minutes) ==="
find /mnt/data/shuoxing/vllm_frame_select -name "*.yaml" -type f -amin -10 2>/dev/null